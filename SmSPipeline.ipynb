{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "class DataExtraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_list):\n",
    "        self.features_list = features_list\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        retour = X\n",
    "        for feature_name, feature_function in self.features_list.items():\n",
    "            retour[feature_name] = X[\"text\"].apply(feature_function)\n",
    "        retour = retour.drop(columns = \"text\")\n",
    "        return retour\n",
    "\n",
    "def get_dictionnaire(string_list):\n",
    "    features = {\n",
    "        \"taille_phrase\":lambda x: len(x),\n",
    "        \"Nombre_mot\":lambda x: len(x.split()),\n",
    "        \"email\": lambda x: len(re.findall(r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}', x)) > 0,\n",
    "        \"presence_monnaie\": lambda x: 1 if re.search(r'[\\$\\€\\£]', x) else 0 ,\n",
    "        \"presence telephone\": lambda x: 1 if re.search(r'\\b\\d{10,}\\b', x) else 0,\n",
    "        \"presence_caratere_speciaux\": lambda x: 1 if re.search(r'[!@#$%^&*(),.?\":{}|<>]', x) else 0,\n",
    "        \"proportion_majuscule\": lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0,\n",
    "        \"presence_lien\": lambda x: 1 if re.search(r'\\b(http|www)\\S+', x) else 0\n",
    "    }\n",
    "    if string_list == \"all\":\n",
    "        return features\n",
    "    elif string_list == \"combination\":\n",
    "        # Générer toutes les combinaisons possibles\n",
    "        all_combinations = []\n",
    "        for r in range(1, len(features) + 1):\n",
    "            combinations_r = list(combinations(features.keys(), r))\n",
    "            all_combinations.extend(combinations_r)\n",
    "\n",
    "        # Créer un dictionnaire de toutes les combinaisons\n",
    "        combinations_dict = {}\n",
    "        for i, combo in enumerate(all_combinations, 1):\n",
    "            combinations_dict[f\"combination_{i}\"] = {k: features[k] for k in combo}\n",
    "        return combinations_dict\n",
    "    else:\n",
    "        dict = {}\n",
    "        try:\n",
    "            for key in string_list:\n",
    "                try:\n",
    "                    dict[key] = features[key]\n",
    "                except:\n",
    "                    print(f\"La fonction {key} n'existe pas dans le dictionnaire\")\n",
    "        except:\n",
    "            print(f\"La fonction demande une liste de string\")\n",
    "        return dict\n",
    "            \n",
    "\n",
    "def GenerateModel(features_names, model, data,vectorizer=TfidfVectorizer(stop_words=\"english\"), scaler=StandardScaler()) :\n",
    "    target = data[\"spam\"]\n",
    "    data = data.drop(columns=[\"spam\"])\n",
    "    featurePipe = Pipeline(steps=[(\"extraction feature\",DataExtraction(features_names)),(\"inputing\",SimpleImputer(strategy=\"mean\")),(\"scaling\",scaler)])\n",
    "    preparation = ColumnTransformer(transformers=\n",
    "                              [(\"features\",featurePipe,[\"text\"]),\n",
    "                               (\"vectorisation\",vectorizer,\"text\")]\n",
    "                              )\n",
    "\n",
    "    modelPipe = Pipeline(steps=[(\"prep données\",preparation),(\"model\",model)])\n",
    "    modelPipe.fit(data,target)\n",
    "    return modelPipe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BD1.txt\",sep=\"\\t\",header=None,names=[\"spam\",\"text\"])\n",
    "y1 = df[\"spam\"]\n",
    "X1 = df\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1,y1 , test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerateModel(model=LinearSVC(),data=X1_train, features_names=get_dictionnaire([\"taille_phrase\", \"Nombre_mot\", \"email\", \"presence_monnaie\", \"presence telephone\", \"presence_caratere_speciaux\", \"proportion_majuscule\", \"presence_lien\"]))\n",
    "print(classification_report(y1_test,model.predict(X1_test)))\n",
    "print(model.predict(pd.DataFrame(['You won 200 billion dollars, call now!', 'Hi, how are you?'], columns=[\"text\"])))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model = GenerateModel(model=RandomForestClassifier(),data=X1_train, features_names=get_dictionnaire(\"all\"))\n",
    "print(classification_report(y1_test,model.predict(X1_test)))\n",
    "print(model.predict(pd.DataFrame(['You won 200 billion dollars, call now!', 'Hi, how are you?'], columns=[\"text\"])))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de modèle pour les 255 combinaisons de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.base import clone\n",
    "\n",
    "def extract_metrics(row):\n",
    "    metrics = {}\n",
    "    for class_name, values in row.items():\n",
    "        if not isinstance(values, float):\n",
    "            for metric, value in values.items():\n",
    "                if class_name in ['ham', 'spam']:\n",
    "                    metrics[f'{metric}_{class_name}'] = value\n",
    "    return pd.Series(metrics)\n",
    "\n",
    "def calculate_precisions_for_all_combinations(X_train, X_test, y_test, model=LinearSVC(), scaler=StandardScaler()):\n",
    "    results_df = pd.DataFrame(columns=['combination', 'accuracy', 'time'])\n",
    "    combinations_dict = get_dictionnaire(\"combination\")\n",
    "    for combination, dict in combinations_dict.items():\n",
    "        start_time = time.time()\n",
    "        # Create a fresh instance of the model for each iteration\n",
    "        model_instance = clone(model)\n",
    "        pipeline = GenerateModel(model=model_instance, data=X_train, features_names=dict, scaler=scaler)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        accuracy = classification_report(y_test, pipeline.predict(X_test), output_dict=True)\n",
    "        results_df = pd.concat([\n",
    "            results_df, \n",
    "            pd.DataFrame({\n",
    "                'combination': [list(dict.keys())], \n",
    "                'accuracy': [accuracy],\n",
    "                'time': [training_time]\n",
    "            })\n",
    "        ])\n",
    "    results_df.reset_index(drop=True, inplace=True)\n",
    "    new_columns = results_df[\"accuracy\"].apply(extract_metrics)\n",
    "    df_precisions = pd.concat([results_df, new_columns], axis=1)\n",
    "    return df_precisions[[\"combination\", \"accuracy\", \"time\", \"recall_ham\", \"recall_spam\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "df_linear = calculate_precisions_for_all_combinations(X1_train,  X1_test, y1_test, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "df_naive_bayes: DataFrame = calculate_precisions_for_all_combinations(X1_train,  X1_test, y1_test, model=model, scaler=MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "df_naive_bayes: DataFrame = calculate_precisions_for_all_combinations(X1_train,  X1_test, y1_test, model=model, scaler=MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logistic_regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
