{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../SMSSpamCollection.txt\", delimiter=\"\\t\", header=None, names=[\"spam\", \"text\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>ham</td>\n",
       "      <td>So dont use hook up any how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wah... Okie okie... Muz make use of e unlimite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>spam</td>\n",
       "      <td>For ur chance to win a £250 wkly shopping spre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just arrived, see you in a couple days &amp;lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>ham</td>\n",
       "      <td>I haven't forgotten you, i might have a couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm reaching home in 5 min.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm a guy, browsin is compulsory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ham</td>\n",
       "      <td>Up to ü... Ü wan come then come lor... But i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>ham</td>\n",
       "      <td>Double eviction this week - Spiral and Michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>ham</td>\n",
       "      <td>GOD ASKED, \"What is forgiveness?\" A little chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text\n",
       "2049   ham                        So dont use hook up any how\n",
       "1905   ham  Wah... Okie okie... Muz make use of e unlimite...\n",
       "4584  spam  For ur chance to win a £250 wkly shopping spre...\n",
       "2784   ham       Just arrived, see you in a couple days &lt;3\n",
       "3344   ham  I haven't forgotten you, i might have a couple...\n",
       "...    ...                                                ...\n",
       "4008   ham                        I'm reaching home in 5 min.\n",
       "1482   ham                   I'm a guy, browsin is compulsory\n",
       "993    ham  Up to ü... Ü wan come then come lor... But i d...\n",
       "4225   ham  Double eviction this week - Spiral and Michael...\n",
       "3760   ham  GOD ASKED, \"What is forgiveness?\" A little chi...\n",
       "\n",
       "[2786 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeData = len(df.index)\n",
    "trainSize = int(0.5*sizeData)\n",
    "trainDF = df.sample(trainSize)\n",
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      spam                                               text\n",
      "4584  spam  for ur chance to win a £250 wkly shopping spre...\n",
      "598   spam  you have an important customer service announc...\n",
      "1050  spam  18 days to euro2004 kickoff! u will be kept in...\n",
      "4376  spam  ur tonexs subscription has been renewed and yo...\n",
      "1154  spam  1000's of girls many local 2 u who r virgins 2...\n",
      "      count\n",
      "to      350\n",
      "a       199\n",
      "call    166\n",
      "you     132\n",
      "your    125\n",
      "     spam                                               text\n",
      "2049  ham                        so dont use hook up any how\n",
      "1905  ham  wah... okie okie... muz make use of e unlimite...\n",
      "2784  ham       just arrived, see you in a couple days &lt;3\n",
      "3344  ham  i haven't forgotten you, i might have a couple...\n",
      "3434  ham  christmas is an occasion that is celebrated as...\n",
      "     count\n",
      "i     1092\n",
      "you    840\n",
      "to     788\n",
      "a      539\n",
      "the    533\n",
      "      count_spam  count_ham\n",
      "to           350      788.0\n",
      "a            199      539.0\n",
      "call         166      113.0\n",
      "you          132      840.0\n",
      "your         125      209.0\n",
      "      count_spam  count_ham  frequence\n",
      "to           350      788.0   1.020057\n",
      "a            199      539.0   0.847904\n",
      "call         166      113.0   3.373745\n",
      "you          132      840.0   0.360892\n",
      "your         125      209.0   1.373556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melos\\AppData\\Local\\Temp\\ipykernel_22344\\245926628.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainDFSpam[\"text\"]=trainDFSpam[\"text\"].str.lower()\n",
      "C:\\Users\\melos\\AppData\\Local\\Temp\\ipykernel_22344\\245926628.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainDFHam[\"text\"]=trainDFHam[\"text\"].str.lower()\n"
     ]
    }
   ],
   "source": [
    "trainDFSpam = trainDF[trainDF[\"spam\"]==\"spam\"]\n",
    "trainDFSpam[\"text\"]=trainDFSpam[\"text\"].str.lower()\n",
    "dfSplitSpam = trainDFSpam.text.str.split(expand=True).stack().value_counts().to_frame()\n",
    "\n",
    "trainDFHam = trainDF[trainDF[\"spam\"]==\"ham\"]\n",
    "trainDFHam[\"text\"]=trainDFHam[\"text\"].str.lower()\n",
    "dfSplitHam = trainDFHam.text.str.split(expand=True).stack().value_counts().to_frame()\n",
    "\n",
    "total = dfSplitSpam.join(dfSplitHam,lsuffix='_spam', rsuffix='_ham')\n",
    "total.fillna(0.001,inplace=True)\n",
    "spamTotal=total[\"count_spam\"].sum()\n",
    "hamTotal = total[\"count_ham\"].sum()\n",
    "total[\"frequence\"]=(total[\"count_spam\"]/spamTotal)/(total[\"count_ham\"]/hamTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melos\\AppData\\Local\\Temp\\ipykernel_22344\\554863744.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  p_document_spam = np.log(p_spam)  # Log de P(spam)\n",
      "C:\\Users\\melos\\AppData\\Local\\Temp\\ipykernel_22344\\554863744.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  p_document_ham = np.log(p_ham)  # Log de P(ham)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le document 'for ur chance to win a £250 wkly shopping' est classé comme : ham\n",
      "Précision du modèle : 86.59%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Étape 1 : Préparer les données\n",
    "# Imaginons que tu aies déjà ton DataFrame 'trainDF' avec les colonnes 'text' et 'spam' où 'spam' = 1 pour les spams et 'ham' = 0 pour les non-spams.\n",
    "\n",
    "# Filtrage des messages spam et non-spam\n",
    "trainDFSpam = trainDF[trainDF[\"spam\"] == 1]\n",
    "trainDFHam = trainDF[trainDF[\"spam\"] == 0]\n",
    "\n",
    "# Convertir les textes en minuscules\n",
    "trainDFSpam[\"text\"] = trainDFSpam[\"text\"].str.lower()\n",
    "trainDFHam[\"text\"] = trainDFHam[\"text\"].str.lower()\n",
    "\n",
    "# Compter les occurrences des mots\n",
    "dfSplitSpam = trainDFSpam.text.str.split(expand=True).stack().value_counts().to_frame()\n",
    "dfSplitHam = trainDFHam.text.str.split(expand=True).stack().value_counts().to_frame()\n",
    "\n",
    "# Fusionner les comptages des mots\n",
    "total = dfSplitSpam.join(dfSplitHam, lsuffix='_spam', rsuffix='_ham').fillna(0.001)\n",
    "\n",
    "# Calculer la fréquence de chaque mot dans chaque classe\n",
    "spamTotal = total[\"count_spam\"].sum()\n",
    "hamTotal = total[\"count_ham\"].sum()\n",
    "\n",
    "total[\"p_spam\"] = total[\"count_spam\"] / spamTotal\n",
    "total[\"p_ham\"] = total[\"count_ham\"] / hamTotal\n",
    "\n",
    "# Étape 2 : Calculer les probabilités a priori (P(spam) et P(ham))\n",
    "total_documents = len(trainDF)  # Nombre total de documents\n",
    "p_spam = len(trainDFSpam) / total_documents  # Probabilité a priori d'un document spam\n",
    "p_ham = len(trainDFHam) / total_documents  # Probabilité a priori d'un document ham\n",
    "\n",
    "# Étape 3 : Calculer les probabilités conditionnelles pour chaque mot\n",
    "total[\"p_spam\"] = total[\"count_spam\"] / spamTotal\n",
    "total[\"p_ham\"] = total[\"count_ham\"] / hamTotal\n",
    "\n",
    "# Étape 4 : Fonction pour calculer les probabilités d'un document\n",
    "def calculate_probabilities(document, p_spam, p_ham, total):\n",
    "    p_document_spam = np.log(p_spam)  # Log de P(spam)\n",
    "    p_document_ham = np.log(p_ham)  # Log de P(ham)\n",
    "\n",
    "    # Calcul des probabilités conditionnelles pour chaque mot du document\n",
    "    for word in document.split():\n",
    "        if word in total.index:\n",
    "            p_document_spam += np.log(total.loc[word, 'p_spam'])\n",
    "            p_document_ham += np.log(total.loc[word, 'p_ham'])\n",
    "        else:\n",
    "            p_document_spam += np.log(0.001)  # Lissage pour les mots inconnus\n",
    "            p_document_ham += np.log(0.001)\n",
    "    \n",
    "    return p_document_spam, p_document_ham\n",
    "\n",
    "# Étape 5 : Fonction pour faire la prédiction\n",
    "def predict(document, p_spam, p_ham, total):\n",
    "    p_spam_doc, p_ham_doc = calculate_probabilities(document, p_spam, p_ham, total)\n",
    "    if p_spam_doc > p_ham_doc:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\"\n",
    "\n",
    "# Exemple d'utilisation : prédire pour un nouveau document\n",
    "test_document = \"for ur chance to win a £250 wkly shopping\"\n",
    "prediction = predict(test_document, p_spam, p_ham, total)\n",
    "print(f\"Le document '{test_document}' est classé comme : {prediction}\")\n",
    "\n",
    "# Étape 6 : Évaluation du modèle\n",
    "# Prédire pour tous les documents de test et comparer avec les vraies étiquettes\n",
    "correct_predictions = 0\n",
    "for _, row in df.iterrows():\n",
    "    predicted_label = predict(row['text'], p_spam, p_ham, total)\n",
    "    if predicted_label == row['spam']:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(df)\n",
    "print(f\"Précision du modèle : {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
